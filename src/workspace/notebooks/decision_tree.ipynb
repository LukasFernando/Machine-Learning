{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../datasets/student_performance.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path, delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_str_value_to_int(df:pd.DataFrame, columns:list):\n",
    "    for column in columns:\n",
    "        # unique_values = list(df[column].unique())\n",
    "        if 'yes' in list(df[column].unique()):\n",
    "            unique_values = ['no', 'yes']\n",
    "        # if len(unique_values) == 2:\n",
    "            df[column] = df[column].apply(lambda x: unique_values.index(str(x).lower()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_columns = [\n",
    "    \"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\", \"Mjob\", \"Fjob\", \n",
    "    \"reason\", \"guardian\", \"schoolsup\", \"famsup\", \"paid\", \"activities\", \n",
    "    \"nursery\", \"higher\", \"internet\", \"romantic\"\n",
    "]\n",
    "\n",
    "df = two_str_value_to_int(df, str_columns)\n",
    "df[str_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in str_columns:\n",
    "    print(f'column = {column} || unique values = {list(df[column].unique())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "after = len(df)\n",
    "\n",
    "print(f'Count before drop duplicates: {before}')\n",
    "print(f'Count after drop duplicates: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Nota (0 a 10) | Nota GPA (Escala de 4.0) | Nota Letra |\n",
    "|---------------------|--------------------------|------------|\n",
    "| 9.0 a 10.0          | 4.0                      | A          |\n",
    "| 8.0 a 8.9           | 3.0 - 3.9                | B          |\n",
    "| 7.0 a 7.9           | 2.0 - 2.9                | C          |\n",
    "| 6.0 a 6.9           | 1.0 - 1.9                | D          |\n",
    "| 0 a 5.9             | 0.0                      | F          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['G2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GPA_result'] = df['G2'].apply(lambda x: 'PASS' if int(x)/5 >= 2 else 'FAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['G1', 'G2', 'G3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for c in df.columns:\n",
    "    if c.startswith('Fjob'):\n",
    "        columns.append(c)\n",
    "\n",
    "df[columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def logs(dt, y_test, X_test, y_train):\n",
    "    # Predição\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    # Acurácia\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Acurácia: {:.2f}\".format(acc))\n",
    "\n",
    "    # Matriz de confusão\n",
    "    print('Matriz de Confusão')\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=y_train.unique())\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_train.unique())\n",
    "    disp.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_X = [\n",
    "    'age', # student's age (numeric: from 15 to 22)\n",
    "    'Medu', # mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "    'Fedu', # father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "    'traveltime', # home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "    'studytime', # weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "    'failures', # number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "    'schoolsup', # extra educational support (binary: yes or no)\n",
    "    'famsup', # family educational support (binary: yes or no)\n",
    "    'paid', # extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "    'activities', # extra-curricular activities (binary: yes or no)\n",
    "    'nursery', # attended nursery school (binary: yes or no)\n",
    "    'higher', # wants to take higher education (binary: yes or no)\n",
    "    'internet', # Internet access at home (binary: yes or no)\n",
    "    'romantic', # with a romantic relationship (binary: yes or no)\n",
    "    'famrel', # quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "    'freetime', # free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "    'goout', # going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "    # 'Dalc', # workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "    # 'Walc', # weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "    'health', # current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "    'absences', # number of school absences (numeric: from 0 to 93)\n",
    "    # 'G1', # first period grade (numeric: from 0 to 20)\n",
    "    # 'G2', # second period grade (numeric: from 0 to 20)\n",
    "    # 'G3', # final grade (numeric: from 0 to 20, output target)\n",
    "    'school_GP', # student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
    "    'school_MS', # student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
    "    'sex_F', # student's sex (binary: 'F' - female or 'M' - male)\n",
    "    'sex_M', # student's sex (binary: 'F' - female or 'M' - male)\n",
    "    'address_R', # student\\'s home address type (binary: 'U' - urban or 'R' - rural)\n",
    "    'address_U', # student\\'s home address type (binary: 'U' - urban or 'R' - rural)\n",
    "    'famsize_GT3', # family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "    'famsize_LE3', # family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "    'Pstatus_A', # parent\\'s cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "    'Pstatus_T', # parent\\'s cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "    'Mjob_at_home', # mother\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Mjob_health', # mother\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Mjob_other', # mother\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Mjob_services', # mother\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Mjob_teacher', # mother\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Fjob_at_home', # father\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Fjob_health', # father\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Fjob_other', # father\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Fjob_services', # father\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'Fjob_teacher', # father\\'s job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "    'reason_course', # reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "    'reason_home', # reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "    'reason_other', # reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "    'reason_reputation', # reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "    'guardian_father', # student\\'s guardian (nominal: 'mother', 'father' or 'other')\n",
    "    'guardian_mother', # student\\'s guardian (nominal: 'mother', 'father' or 'other')\n",
    "    'guardian_other', # student\\'s guardian (nominal: 'mother', 'father' or 'other')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[columns_to_X]\n",
    "y = df['GPA_result'].map({'PASS':1, 'FAIL':0})\n",
    "# y = y.map({'PASS':1, 'FAIL':0})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dt = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    # criterion='gini',\n",
    "    criterion='entropy',\n",
    "    splitter='best',\n",
    "    max_depth=20,\n",
    "    min_samples_split=0.3,\n",
    "    # min_samples_leaf=0.1,\n",
    "    # min_weight_fraction_leaf=0.01,\n",
    "    max_features='sqrt',\n",
    "    random_state=1,\n",
    "    # max_leaf_nodes=50,\n",
    "    min_impurity_decrease=0.01,\n",
    "    class_weight='balanced',\n",
    "    ccp_alpha=0.001\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "logs(dt=dt, y_test=y_test, X_test=X_test, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dt = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    # criterion='gini',\n",
    "    criterion='entropy',\n",
    "    splitter='best',\n",
    "    max_depth=20,\n",
    "    min_samples_split=0.3,\n",
    "    # min_samples_leaf=0.1,\n",
    "    # min_weight_fraction_leaf=0.01,\n",
    "    # max_features='sqrt',\n",
    "    random_state=1,\n",
    "    # max_leaf_nodes=50,\n",
    "    min_impurity_decrease=0.01,\n",
    "    class_weight='balanced',\n",
    "    ccp_alpha=0.001\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "logs(dt=dt, y_test=y_test, X_test=X_test, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dt = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    # criterion='gini',\n",
    "    criterion='entropy',\n",
    "    splitter='best',\n",
    "    max_depth=20,\n",
    "    min_samples_split=0.2,\n",
    "    # min_samples_leaf=0.1,\n",
    "    # min_weight_fraction_leaf=0.01,\n",
    "    # max_features='sqrt',\n",
    "    random_state=1,\n",
    "    # max_leaf_nodes=50,\n",
    "    # min_impurity_decrease=0.01,\n",
    "    # class_weight='balanced',\n",
    "    ccp_alpha=0.01\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "logs(dt=dt, y_test=y_test, X_test=X_test, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier - Parâmetros Explicados\n",
    "\n",
    "O `DecisionTreeClassifier` do `sklearn.tree` é um modelo de árvore de decisão usado para classificação. Vamos entender cada parâmetro.\n",
    "\n",
    "## Parâmetros:\n",
    "\n",
    "### **1. criterion**\n",
    "Define a função usada para medir a qualidade da divisão.\n",
    "- `\"gini\"`: Usa o índice de Gini para medir a impureza.\n",
    "- `\"entropy\"`: Usa a entropia da teoria da informação.\n",
    "- `\"log_loss\"`: Usa a perda logarítmica (log loss).\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(criterion=\"entropy\")\n",
    "```\n",
    "\n",
    "### **2. splitter**\n",
    "Define a estratégia para escolher onde dividir o nó.\n",
    "- `\"best\"`: Escolhe a melhor divisão baseada no critério.\n",
    "- `\"random\"`: Escolhe uma divisão aleatória entre as melhores.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(splitter=\"random\")\n",
    "```\n",
    "\n",
    "### **3. max_depth**\n",
    "Define a profundidade máxima da árvore. Se `None`, cresce até todas as folhas serem puras ou conterem menos que `min_samples_split` amostras.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(max_depth=5)\n",
    "```\n",
    "\n",
    "### **4. min_samples_split**\n",
    "Número mínimo de amostras para dividir um nó.\n",
    "- Pode ser um número inteiro (quantidade absoluta de amostras).\n",
    "- Pode ser um valor decimal entre 0 e 1 (fração das amostras totais).\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(min_samples_split=10)  # Mínimo 10 amostras para dividir\n",
    "DecisionTreeClassifier(min_samples_split=0.1) # 10% das amostras mínimas\n",
    "```\n",
    "\n",
    "### **5. min_samples_leaf**\n",
    "Número mínimo de amostras em um nó folha.\n",
    "- Pode ser um inteiro ou um valor decimal.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(min_samples_leaf=5) # Mínimo 5 amostras em folhas\n",
    "DecisionTreeClassifier(min_samples_leaf=0.05) # Pelo menos 5% das amostras\n",
    "```\n",
    "\n",
    "### **6. min_weight_fraction_leaf**\n",
    "Peso mínimo que um nó folha deve ter (importante quando há amostras com pesos desbalanceados).\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(min_weight_fraction_leaf=0.01) # Pelo menos 1% do peso total\n",
    "```\n",
    "\n",
    "### **7. max_features**\n",
    "Número máximo de recursos considerados ao dividir um nó.\n",
    "- Pode ser um número inteiro.\n",
    "- `\"auto\"` ou `\"sqrt\"` → usa `sqrt(n_features)`.\n",
    "- `\"log2\"` → usa `log2(n_features)`.\n",
    "- Se `None`, usa todos os recursos.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(max_features=5)\n",
    "DecisionTreeClassifier(max_features=\"sqrt\")\n",
    "```\n",
    "\n",
    "### **8. random_state**\n",
    "Define a semente aleatória para reprodução dos resultados.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(random_state=42)\n",
    "```\n",
    "\n",
    "### **9. max_leaf_nodes**\n",
    "Número máximo de nós folhas. Se `None`, cresce sem limite.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(max_leaf_nodes=50)\n",
    "```\n",
    "\n",
    "### **10. min_impurity_decrease**\n",
    "Redução mínima na impureza necessária para dividir um nó.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(min_impurity_decrease=0.01)\n",
    "```\n",
    "\n",
    "### **11. class_weight**\n",
    "Define pesos para classes desbalanceadas.\n",
    "- `\"balanced\"`: Ajusta automaticamente os pesos baseando-se na distribuição das classes.\n",
    "- Dicionário: `{classe: peso}`.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "DecisionTreeClassifier(class_weight={0: 1, 1: 5}) # Classe 1 tem mais peso\n",
    "```\n",
    "\n",
    "### **12. ccp_alpha**\n",
    "Parâmetro de poda baseado na complexidade da árvore.\n",
    "- Quanto maior o valor, mais poda ocorre.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "DecisionTreeClassifier(ccp_alpha=0.01)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Exemplo Completo**\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    splitter=\"best\",\n",
    "    max_depth=5,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    ccp_alpha=0.01\n",
    ")\n",
    "```\n",
    "\n",
    "Esse modelo cria uma árvore com no máximo 5 níveis de profundidade, usa Gini como critério, divisão baseada na melhor opção e ajusta os pesos das classes automaticamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(model, 'house_price_linear_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
